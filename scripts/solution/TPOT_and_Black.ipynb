{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Being focused on a futur project which takes more time than expected, I'll just dig into 2 new interesting libraries. \n",
    "\n",
    "### TPOT :\n",
    "\n",
    "This library automates the data preparation and training by using genetic algorithms to <b>preprocess</b>, <b>create</b> features and test models with differents parameters. This libraries has plenty of good benefits as it does the reserach in an automated way but the training takes times and doesn't consider Neural Networks. As an introduction, we will try it on a very small and known dataset\n",
    "\n",
    "### Black :\n",
    "\n",
    "This library re-write python file following PEP8 rule. on this one, we will just apply it on a simple python file to see the outcome.\n",
    "\n",
    "# TPOT (<a href=\"https://github.com/EpistasisLab/tpot\">Github</a>)\n",
    "\n",
    "As mentionned previously, TPOT is a Python Automated Machine Learning tool that optimizes machine learning pipelines using genetic programming. This library applies on the following steps:\n",
    "\n",
    "<img src=\"tpot_ml_pipeline.png\"/>\n",
    "\n",
    "To try it, let's test it on a very simple library which is Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_wine()\n",
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset provided by sklearn is not a usual dataset so let's first create dataframes as we usually have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data = dataset.data, columns =dataset.feature_names)\n",
    "\n",
    "y = pd.Series(data = dataset.target)\n",
    "y.name = \"Label\"\n",
    "y = y.map({i : dataset.target_names[i] for i in range(3)}).to_frame()\n",
    "\n",
    "y_ohe = pd.get_dummies(dataset.target)\n",
    "y_ohe.columns = dataset.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  \n",
       "0                          3.92   1065.0  \n",
       "1                          3.40   1050.0  \n",
       "2                          3.17   1185.0  \n",
       "3                          3.45   1480.0  \n",
       "4                          2.93    735.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_0</th>\n",
       "      <th>class_1</th>\n",
       "      <th>class_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_0  class_1  class_2\n",
       "0        1        0        0\n",
       "1        1        0        0\n",
       "2        1        0        0\n",
       "3        1        0        0\n",
       "4        1        0        0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ohe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>class_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>class_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>class_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label\n",
       "0  class_0\n",
       "1  class_0\n",
       "2  class_0\n",
       "3  class_0\n",
       "4  class_0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can split both datas with a trian and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test, y_train_ohe, y_test_ohe = train_test_split(X, y, y_ohe, test_size=0.25, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and not the use of this algorithm is very simple. We jsute have few parameters. As the dataset is very simple, the population chosen is small to have a chance to see an improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: xgboost.XGBClassifier is not available and will not be used by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579ea3a7e9754c939488798671379b00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.9629426129426129\n",
      "Generation 2 - Current best internal CV score: 0.9700854700854702\n",
      "Generation 3 - Current best internal CV score: 0.9700854700854702\n",
      "Generation 4 - Current best internal CV score: 0.9700854700854702\n",
      "Generation 5 - Current best internal CV score: 0.9703703703703704\n",
      "Generation 6 - Current best internal CV score: 0.9703703703703704\n",
      "Generation 7 - Current best internal CV score: 0.9703703703703704\n",
      "Generation 8 - Current best internal CV score: 0.9703703703703704\n",
      "Generation 9 - Current best internal CV score: 0.9703703703703704\n",
      "Generation 10 - Current best internal CV score: 0.9777777777777779\n",
      "\n",
      "Best pipeline: RandomForestClassifier(input_matrix, bootstrap=True, criterion=gini, max_features=0.9000000000000001, min_samples_leaf=2, min_samples_split=19, n_estimators=100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict=None, crossover_rate=0.1, cv=5,\n",
       "        disable_update_check=False, early_stop=None, generations=10,\n",
       "        max_eval_time_mins=5, max_time_mins=None, memory=None,\n",
       "        mutation_rate=0.9, n_jobs=1, offspring_size=None,\n",
       "        periodic_checkpoint_folder=None, population_size=3,\n",
       "        random_state=None, scoring=None, subsample=1.0, use_dask=False,\n",
       "        verbosity=2, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot = TPOTClassifier(generations=10, population_size=3, verbosity=2, n_jobs=1)\n",
    "\n",
    "tpot.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see improvement during training and the best model is provided at the end, we can now test it on a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The genetic algorithm succeed to improve the pre-processing and modeling to get 1 more percent of accuracy. I wanted to try it with dataframe but it doesn't work. I also wanted to pre-process the label to one hot encoded vector but it's also not considered. To finish with this library, we can export the pipeline for futur training :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot.export('tpot_pipeline.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and this is the return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# NOTE: Make sure that the class is labeled 'target' in the data file\n",
    "tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)\n",
    "features = tpot_data.drop('target', axis=1).values\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, tpot_data['target'].values, random_state=None)\n",
    "\n",
    "# Average CV score on the training set was:0.9777777777777779\n",
    "exported_pipeline = RandomForestClassifier(bootstrap=True, criterion=\"gini\", max_features=0.9000000000000001, min_samples_leaf=2, min_samples_split=19, n_estimators=100)\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it for this library. It's a public library on github with a fast growing community so we can expect new features of it in the futur months."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Black  (<a href=\"https://github.com/ambv/black\">Github</a>)\n",
    "\n",
    "Now let's talk about Black. This is not a library as usual. It can be installed as any other library with pip but after the use is only by command line with :\n",
    "\n",
    "<b>black path/to/file.py --args</b>\n",
    "\n",
    "Let's try it on the following code use to train a Deep Q Network with Prioritzed Experience Replay. I modified it to have it non-PEP8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SumTree(object):\n",
    "    \"\"\"\n",
    "    This SumTree code is modified version and the original code is from:\n",
    "    https://github.com/jaara/AI-blog/blob/master/SumTree.py\n",
    "\n",
    "    Story the data with it priority in tree and data frameworks.\n",
    "    \"\"\"\n",
    "    data_pointer = 0\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity  # for all priority values\n",
    "        self.tree = np.zeros(2 * capacity - 1)\n",
    "        # [--------------Parent nodes-------------][-------leaves to recode priority-------]\n",
    "        #             size: capacity - 1                       size: capacity\n",
    "        self.data = np.zeros(capacity, dtype=object)  # for all transitions\n",
    "        # [--------------data frame-------------]\n",
    "        #             size: capacity\n",
    "\n",
    "    def add_new_priority(self, p, data):\n",
    "        \n",
    "        leaf_idx = self.data_pointer + self.capacity - 1\n",
    "        self.data[self.data_pointer] = data  # update data_frame\n",
    "        self.update(leaf_idx, p)  # update tree_frame\n",
    "        self.data_pointer += 1\n",
    "        \n",
    "        if self.data_pointer >= self.capacity:  # replace when exceed the capacity\n",
    "            self.data_pointer = 0\n",
    "\n",
    "    def update(self, tree_idx, p):\n",
    "        \n",
    "        change = p - self.tree[tree_idx]\n",
    "\n",
    "        self.tree[tree_idx] = p\n",
    "        self._propagate_change(tree_idx, change)\n",
    "\n",
    "    def _propagate_change(self, tree_idx, change):\n",
    "        \"\"\"change the sum of priority value in all parent nodes\"\"\"\n",
    "        parent_idx = (tree_idx - 1) // 2\n",
    "        self.tree[parent_idx] += change\n",
    "        if parent_idx != 0:\n",
    "            self._propagate_change(parent_idx, change)\n",
    "\n",
    "    def get_leaf(self, lower_bound):\n",
    "        leaf_idx = self._retrieve(lower_bound)  # search the max leaf priority based on the lower_bound\n",
    "        data_idx = leaf_idx - self.capacity + 1\n",
    "        return [leaf_idx, self.tree[leaf_idx], self.data[data_idx]]\n",
    "\n",
    "    def _retrieve(self, lower_bound, parent_idx=0):\n",
    "        \"\"\"\n",
    "        Tree structure and array storage:\n",
    "\n",
    "        Tree index:\n",
    "             0         -> storing priority sum\n",
    "            / \\\n",
    "          1     2\n",
    "         / \\   / \\\n",
    "        3   4 5   6    -> storing priority for transitions\n",
    "\n",
    "        Array type for storing:\n",
    "        [0,1,2,3,4,5,6]\n",
    "        \"\"\"\n",
    "        left_child_idx = 2 * parent_idx + 1\n",
    "        right_child_idx = left_child_idx + 1\n",
    "\n",
    "        if left_child_idx >= len(self.tree): return parent_idx # end search when no more child\n",
    "        if self.tree[left_child_idx] == self.tree[right_child_idx]:\n",
    "            return self._retrieve(lower_bound, np.random.choice([left_child_idx, right_child_idx]))\n",
    "        if lower_bound <= self.tree[left_child_idx]:  # downward search, always search for a higher priority node\n",
    "            return self._retrieve(lower_bound, left_child_idx)\n",
    "        else:\n",
    "            return self._retrieve(lower_bound - self.tree[left_child_idx], right_child_idx)\n",
    "\n",
    "    @property\n",
    "    def root_priority(self):\n",
    "        return self.tree[0]  # the root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"2018-10-23 16_38_08-Window.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class SumTree(object):\n",
    "    \"\"\"\n",
    "    This SumTree code is modified version and the original code is from:\n",
    "    https://github.com/jaara/AI-blog/blob/master/SumTree.py\n",
    "\n",
    "    Story the data with it priority in tree and data frameworks.\n",
    "    \"\"\"\n",
    "\n",
    "    data_pointer = 0\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity  # for all priority values\n",
    "        self.tree = np.zeros(2 * capacity - 1)\n",
    "        # [--------------Parent nodes-------------][-------leaves to recode priority-------]\n",
    "        #             size: capacity - 1                       size: capacity\n",
    "        self.data = np.zeros(capacity, dtype=object)  # for all transitions\n",
    "        # [--------------data frame-------------]\n",
    "        #             size: capacity\n",
    "\n",
    "    def add_new_priority(self, p, data):\n",
    "\n",
    "        leaf_idx = self.data_pointer + self.capacity - 1\n",
    "        self.data[self.data_pointer] = data  # update data_frame\n",
    "        self.update(leaf_idx, p)  # update tree_frame\n",
    "        self.data_pointer += 1\n",
    "\n",
    "        if self.data_pointer >= self.capacity:  # replace when exceed the capacity\n",
    "            self.data_pointer = 0\n",
    "\n",
    "    def update(self, tree_idx, p):\n",
    "\n",
    "        change = p - self.tree[tree_idx]\n",
    "\n",
    "        self.tree[tree_idx] = p\n",
    "        self._propagate_change(tree_idx, change)\n",
    "\n",
    "    def _propagate_change(self, tree_idx, change):\n",
    "        \"\"\"change the sum of priority value in all parent nodes\"\"\"\n",
    "        parent_idx = (tree_idx - 1) // 2\n",
    "        self.tree[parent_idx] += change\n",
    "        if parent_idx != 0:\n",
    "            self._propagate_change(parent_idx, change)\n",
    "\n",
    "    def get_leaf(self, lower_bound):\n",
    "        leaf_idx = self._retrieve(\n",
    "            lower_bound\n",
    "        )  # search the max leaf priority based on the lower_bound\n",
    "        data_idx = leaf_idx - self.capacity + 1\n",
    "        return [leaf_idx, self.tree[leaf_idx], self.data[data_idx]]\n",
    "\n",
    "    def _retrieve(self, lower_bound, parent_idx=0):\n",
    "        \"\"\"\n",
    "        Tree structure and array storage:\n",
    "\n",
    "        Tree index:\n",
    "             0         -> storing priority sum\n",
    "            / \\\n",
    "          1     2\n",
    "         / \\   / \\\n",
    "        3   4 5   6    -> storing priority for transitions\n",
    "\n",
    "        Array type for storing:\n",
    "        [0,1,2,3,4,5,6]\n",
    "        \"\"\"\n",
    "        left_child_idx = 2 * parent_idx + 1\n",
    "        right_child_idx = left_child_idx + 1\n",
    "\n",
    "        if left_child_idx >= len(self.tree):\n",
    "            return parent_idx  # end search when no more child\n",
    "        if self.tree[left_child_idx] == self.tree[right_child_idx]:\n",
    "            return self._retrieve(\n",
    "                lower_bound, np.random.choice([left_child_idx, right_child_idx])\n",
    "            )\n",
    "        if (\n",
    "            lower_bound <= self.tree[left_child_idx]\n",
    "        ):  # downward search, always search for a higher priority node\n",
    "            return self._retrieve(lower_bound, left_child_idx)\n",
    "        else:\n",
    "            return self._retrieve(\n",
    "                lower_bound - self.tree[left_child_idx], right_child_idx\n",
    "            )\n",
    "\n",
    "    @property\n",
    "    def root_priority(self):\n",
    "        return self.tree[0]  # the root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that it considered already several PEP8 points like :\n",
    "- 2 lines before to declare a Class\n",
    "- 1 line before to declare a Method\n",
    "- less than 88 characters per lines (but sometimes it creates strange choices like :\n",
    "<code>\n",
    "if (\n",
    "    lower_bound <= self.tree[left_child_idx]\n",
    "):  # downward search, always search for a higher priority node\n",
    "</code>\n",
    "\n",
    "instead of\n",
    "<code>\n",
    "if (lower_bound <= self.tree[left_child_idx]):\n",
    "    # downward search, always search for a higher priority node\n",
    "</code>\n",
    "\n",
    "but in average the result is fine. Several points are logical and must be applied by all developper but it can support codes to have all the same layout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "This quick notebook presents 2 simple but usefull libraries. One is mainly done for ML purpose and simplify some preparation steps. It's still a bit restricted as it's not working with dataframe (we should convert it first to Numpy matrices). It doesn't accept labeled target (or at least in bugged when doint the scoring on the test set) or One-Hot-Encoded matrices. This will most probably evolve in the near futur so let's keep an eye on it.\n",
    "\n",
    "Regarding Black, it's a more global library which may be usefull in company to align codes between devs. Even if it applies simple rules, it has the benefit to still align it the same way. It has several option to adjust line lenght, varaible/class naming and so on."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
